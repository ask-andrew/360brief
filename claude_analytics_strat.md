This is an exciting challenge! Let me think about truly differentiated, actionable insights that go beyond basic metrics. I'll organize these into thematic groups with visualization ideas and LLM-powered recommendations.

## **üéØ LEVEL 10 METRICS FRAMEWORK**

---

## **Theme 1: "Relationship Velocity & Health"**

### **Metrics:**

**1. Response Time Reciprocity Score**
- Track how quickly you respond to key contacts vs. how quickly they respond to you
- Identify asymmetric relationships (you respond in hours, they take days)
- **Visualization**: Scatter plot with contacts plotted by "Your Response Time" (Y-axis) vs "Their Response Time" (X-axis). Quadrants labeled:
  - "Mutual Priority" (fast/fast)
  - "You're Chasing" (fast/slow)
  - "They're Chasing" (slow/fast)
  - "Low Engagement" (slow/slow)

**2. Conversation Thread Decay Rate**
- Measure how many email threads die after your last message vs. continue after theirs
- Identifies where you're ending conversations vs. driving them forward
- **Visualization**: Horizontal bar chart showing "Thread Death Rate" by contact/domain
- **LLM Recommendation**: *"You've ended 73% of threads with [Client X] in the past 30 days. Consider if this signals disengagement or if you need to ask more open-ended questions."*

**3. Collaboration Temperature Map**
- Combine: email frequency + meeting frequency + response times + CC patterns
- Creates a "heat score" showing relationship intensity over time
- **Visualization**: Line graph with shaded regions showing "warming" or "cooling" relationships
- **LLM Recommendation**: *"Your collaboration with Engineering team has cooled 40% this quarter. Schedule a sync or increase visibility on [Project X]."*

---

## **Theme 2: "Attention Economics"**

### **Metrics:**

**4. Peak Cognitive Load Windows**
- Analyze: meeting density + email volume + response times during different hours
- Identify when you're most overwhelmed vs. most effective
- **Visualization**: Heatmap showing hours of day (X) vs. days of week (Y), color-coded by "Cognitive Load Score"
- **LLM Recommendation**: *"Your response quality drops 60% after 3 PM on days with 5+ meetings. Block 2-4 PM for focused work or move meetings to mornings."*

**5. Context Switch Tax**
- Count: topic changes per hour (derived from email subjects/meeting titles)
- Measure fragmentation of your day
- **Visualization**: Stacked area chart showing "Time Spent in Each Context" throughout a typical week
- **LLM Recommendation**: *"You switch contexts 23 times per day on average. Try batching [Client Communications] into two dedicated windows instead of throughout the day."*

**6. "Reply Debt" Accumulation Curve**
- Track unanswered emails over time by sender importance (weighted)
- Shows where obligations are piling up
- **Visualization**: Area chart showing accumulating "debt" over time, segmented by sender category (Clients, Team, Leadership, Partners)
- **LLM Recommendation**: *"You have 12 unanswered emails from direct reports averaging 4 days old. Schedule office hours or batch responses Friday morning."*

---

## **Theme 3: "Leadership Patterns"**

### **Metrics:**

**7. Delegation vs. Execution Ratio**
- Analyze: emails/messages where you're asking vs. doing vs. deciding
- Derived from verb patterns: "Can you..." vs "I will..." vs "I've decided..."
- **Visualization**: Pie chart with trend line showing shift over time
- **LLM Recommendation**: *"Your 'execution' emails increased 35% this month. You're doing more vs. delegating. Consider what tasks [Team Member] could own."*

**8. Meeting ROI Score**
- Calculate: (Action items generated + decisions made) / (meeting duration √ó # attendees)
- Identifies high-value vs. low-value meetings
- **Visualization**: Bubble chart with meetings plotted by "Duration" (X) vs "Value Generated" (Y), sized by attendee count
- **LLM Recommendation**: *"Your weekly All-Hands has 0.2 ROI (bottom 10%). Consider: shorter duration, clearer agenda, or async update instead."*

**9. Communication Equity Index**
- Measure: How evenly is your time distributed across direct reports?
- Flags if some team members are getting significantly more/less attention
- **Visualization**: Donut chart showing % of your communication time with each direct report, with "expected equal share" line
- **LLM Recommendation**: *"You've communicated 4√ó more with [Sarah] than [David] this month. Check if David needs more support or if delegation is unbalanced."*

---

## **Theme 4: "Strategic Focus"**

### **Metrics:**

**10. Time vs. Priority Misalignment Score**
- Cross-reference: stated company/team priorities (OKRs, goals) vs. where you actually spend time
- Derived from: email subjects, meeting titles, calendar categorization
- **Visualization**: Sankey diagram flowing from "Stated Priorities" to "Actual Time Allocation"
- **LLM Recommendation**: *"You allocated 8% of time to 'Product Innovation' but it's your #1 stated priority. Consider declining meetings in [Category X] to rebalance."*

**11. Reactive vs. Proactive Communication Ratio**
- Analyze: Are you replying to others or initiating conversations?
- Track first message in thread vs. responses
- **Visualization**: Stacked bar chart by week showing Reactive (bottom) vs. Proactive (top)
- **LLM Recommendation**: *"You're 85% reactive this month. Block time Monday mornings to proactively reach out on [Strategic Initiative]."*

**12. "Firefighting" Trend**
- Count emails/meetings containing: "urgent," "ASAP," "emergency," "critical issue"
- Shows if you're in crisis mode or strategic mode
- **Visualization**: Line graph with highlighted "firefighting spikes" and rolling 30-day average
- **LLM Recommendation**: *"Firefighting increased 40% this quarter. Root cause: [Client X issues]. Consider: dedicated support resource or process improvement."*

---

## **Theme 5: "Personal Sustainability"**

### **Metrics:**

**13. Weekend/Evening Creep Index**
- Track: % of emails sent/read outside work hours over time
- Flags burnout risk
- **Visualization**: Area chart showing "After Hours Activity %" with "healthy baseline" reference line
- **LLM Recommendation**: *"You've sent 43 emails after 8 PM this month (+120% vs. last quarter). This pattern correlates with stress. Try: email scheduling or strict cutoff times."*

**14. Single-Player vs. Collaborative Time**
- Analyze: Time in solo work (no meetings, no comms) vs. collaborative activities
- Derived from calendar gaps + low-email periods
- **Visualization**: Weekly calendar heatmap with "focus time" blocks highlighted
- **LLM Recommendation**: *"You had only 3 hours of uninterrupted focus time this week. Block 'Deep Work' time Tuesday/Thursday mornings before meetings start."*

**15. Energy Signature Pattern**
- Combine: response times, email length, sentiment, meeting participation
- Creates a "daily energy curve" showing when you're most effective
- **Visualization**: Line graph showing your "energy score" by hour of day, averaged over 30 days
- **LLM Recommendation**: *"Your energy peaks 9-11 AM. Schedule strategic work then. Avoid decision-making after 4 PM when your response quality drops 40%."*

---

## **Theme 6: "Network Intelligence"**

### **Metrics:**

**16. Connector Score**
- Analyze: How often do you introduce people (CC patterns, "meet X" emails)
- Identifies if you're a network hub or isolated
- **Visualization**: Network graph showing you at center, with lines to contacts, weighted by introduction frequency
- **LLM Recommendation**: *"You've made 0 introductions this quarter. Your network value compounds when you connect others. Consider introducing [Sarah] to [Client X]."*

**17. Information Bottleneck Index**
- Identify: Emails where you're the only link between groups (unique CC position)
- Shows where you're a single point of failure
- **Visualization**: Chord diagram showing information flow between teams, with you as critical bridge
- **LLM Recommendation**: *"You're the sole link between Engineering and Sales in 67% of cases. Risk: vacation coverage. Consider: weekly sync between teams."*

**18. Influence Ripple Effect**
- Track: When you send an email, how many subsequent messages/meetings does it generate?
- Measures your organizational leverage
- **Visualization**: Scatter plot of your messages (X: message count, Y: ripple effect multiplier)
- **LLM Recommendation**: *"Your emails to Leadership generate 8√ó more follow-up activity than emails to vendors. Prioritize strategic internal communication."*

---

## **üé® VISUALIZATION INNOVATIONS**

### **Dashboard Layout Ideas:**

**1. "Command Center" View**
- Central hero metric: "Strategic Focus Score" (0-100)
- Surrounding cards: Top 3 risks, Top 3 opportunities
- Bottom: Trending metrics with sparklines

**2. "Time Travel" Comparison**
- Split screen: "This Week" vs "Last Month" vs "Last Quarter"
- Highlights: What's improving, what's degrading
- Predictive: "If this trend continues..."

**3. "Relationship Portfolio" View**
- Grid of key contacts with mini-cards showing:
  - Response time reciprocity
  - Communication frequency
  - Sentiment trend
  - Last interaction date
- Color-coded: Green (healthy), Yellow (needs attention), Red (at risk)

---

## **ü§ñ LLM RECOMMENDATION ENGINE**

### **Architecture:**

**Input to LLM:**
```javascript
{
  "metric_name": "Response Time Reciprocity",
  "user_score": 2.3,  // They take 2.3√ó longer to respond to you
  "contact": "Client X",
  "trend": "worsening",  // Was 1.8√ó last month
  "context": {
    "upcoming_renewal": true,
    "revenue_at_risk": "$250K",
    "recent_meeting_sentiment": "neutral"
  }
}
```

**LLM Prompt Template:**
```
You are a strategic communication advisor. Based on this metric:
- Identify the business risk or opportunity
- Suggest ONE specific, actionable step
- Explain the reasoning in 2 sentences max
- Tone: Direct, empathetic, executive-focused

Metric: [metric_data]
```

**Output:**
```
‚ö†Ô∏è Client X is taking 130% longer to respond (trend: worsening). 
With $250K renewal at risk, schedule a face-to-face check-in this 
week to surface concerns before they escalate.
```

---

## **üíé UNIQUE DIFFERENTIATORS**

These metrics are **unrivaled** because they:

1. **Actionable**: Every metric has a clear "so what" and "now what"
2. **Predictive**: Identify problems before they explode
3. **Behavioral**: Focus on patterns, not just counts
4. **Relational**: Understand dynamics between people, not just volume
5. **Strategic**: Connect day-to-day actions to business outcomes

**No other tool analyzes:**
- Response time reciprocity
- Thread decay rates
- Context switch tax
- Delegation ratios
- Influence ripple effects

This positions 360brief as a **strategic intelligence layer**, not just another analytics dashboard.

---
Claude's guidance on building:
Excellent! Let me review Gemini's data pipeline approach and provide improvements and clarifications for your coding tools.

## **üîç REVIEW & IMPROVEMENTS**

Gemini's approach is **solid and comprehensive**. Here are key enhancements and clarifications:

---

## **üèóÔ∏è CRITICAL ARCHITECTURE IMPROVEMENTS**

### **1. Data Storage Structure (PRIORITY)**

**Gemini's Approach:** Feature Store concept
**Enhancement:** Implement a **layered data architecture**

```
Layer 1: RAW DATA (Immutable)
‚îú‚îÄ‚îÄ emails_raw
‚îú‚îÄ‚îÄ calendar_raw
‚îî‚îÄ‚îÄ slack_raw

Layer 2: PROCESSED DATA (Normalized)
‚îú‚îÄ‚îÄ threads (email threading logic applied)
‚îú‚îÄ‚îÄ participants (unified contact records)
‚îú‚îÄ‚îÄ events_timeline (chronological stream)
‚îî‚îÄ‚îÄ relationships (contact-to-contact mapping)

Layer 3: ENRICHED DATA (LLM-enhanced)
‚îú‚îÄ‚îÄ content_classifications (topics, intents, sentiment)
‚îú‚îÄ‚îÄ action_items
‚îî‚îÄ‚îÄ decisions

Layer 4: METRICS (Calculated)
‚îú‚îÄ‚îÄ daily_metrics
‚îú‚îÄ‚îÄ weekly_metrics
‚îî‚îÄ‚îÄ historical_trends
```

**Why This Matters:**
- **Incremental processing**: Don't reprocess everything when new data arrives
- **Debugging**: Can trace back from metric ‚Üí enriched ‚Üí processed ‚Üí raw
- **Cost optimization**: Only run expensive LLM operations once

---

### **2. THREAD RECONSTRUCTION (CRITICAL FIX)**

**Gemini's approach is correct but incomplete.** Here's the battle-tested algorithm:

```python
def reconstruct_threads(emails):
    """
    Thread reconstruction using Message-ID, In-Reply-To, References
    """
    threads = {}
    message_map = {}
    
    # First pass: Index all messages
    for email in emails:
        message_map[email['message_id']] = email
    
    # Second pass: Build threads
    for email in emails:
        thread_id = None
        
        # Check if replying to existing message
        if email.get('in_reply_to'):
            parent_id = email['in_reply_to']
            if parent_id in message_map:
                thread_id = message_map[parent_id].get('thread_id')
        
        # Check References header (more reliable)
        if not thread_id and email.get('references'):
            refs = email['references'].split()
            for ref_id in refs:
                if ref_id in message_map:
                    thread_id = message_map[ref_id].get('thread_id')
                    break
        
        # Fallback: Subject-based threading (fuzzy match)
        if not thread_id:
            subject = normalize_subject(email['subject'])
            thread_id = find_thread_by_subject(threads, subject)
        
        # Create new thread if nothing found
        if not thread_id:
            thread_id = email['message_id']
        
        email['thread_id'] = thread_id
        threads.setdefault(thread_id, []).append(email)
    
    return threads

def normalize_subject(subject):
    """Remove Re:, Fwd:, [tags], etc."""
    import re
    subject = re.sub(r'^(Re|Fwd|RE|FW):\s*', '', subject, flags=re.IGNORECASE)
    subject = re.sub(r'\[.*?\]', '', subject)
    return subject.strip().lower()
```

**Critical Addition:** Handle **Gmail's threading behavior** which groups differently than Message-ID headers suggest.

---

### **3. PARTICIPANT NORMALIZATION (ENHANCED)**

**Gemini mentions this but lacks detail.** This is critical for accurate metrics:

```python
class ContactUnifier:
    """
    Unify different email addresses to single contacts
    """
    def __init__(self):
        self.email_to_canonical = {}
        self.canonical_to_profile = {}
    
    def add_email(self, email, name=None, domain=None):
        """
        Links: john.doe@company.com, john@company.com, jdoe@company.com
        ‚Üí Canonical: "John Doe <john.doe@company.com>"
        """
        canonical = self._find_canonical(email, domain)
        
        if canonical not in self.canonical_to_profile:
            self.canonical_to_profile[canonical] = {
                'emails': set(),
                'names': set(),
                'primary_email': email,
                'domain': domain
            }
        
        self.email_to_canonical[email] = canonical
        self.canonical_to_profile[canonical]['emails'].add(email)
        if name:
            self.canonical_to_profile[canonical]['names'].add(name)
    
    def _find_canonical(self, email, domain):
        """Smart matching logic"""
        # Check if email already maps to someone
        if email in self.email_to_canonical:
            return self.email_to_canonical[email]
        
        # Check same domain variations
        local_part = email.split('@')[0]
        for existing_email, canonical in self.email_to_canonical.items():
            if existing_email.split('@')[0] == local_part:
                if existing_email.split('@')[1] == domain:
                    return canonical
        
        return email  # New canonical
```

**Why Critical:** Without this, "John Doe" becomes 3 different people if he emails from 3 addresses.

---

### **4. LLM INTEGRATION STRATEGY (MAJOR ENHANCEMENT)**

**Gemini's async/batch approach is correct, but add this:**

**Tiered LLM Strategy** (Cost + Speed optimization):

```python
class LLMProcessor:
    """
    Use appropriate model for each task
    """
    
    def classify_content(self, text):
        """
        Tier 1: Simple keyword matching (free, instant)
        Tier 2: Small local model (cheap, fast)
        Tier 3: GPT-4/Claude for complex cases (expensive, accurate)
        """
        # Try simple rules first
        if simple_intent := self._keyword_classification(text):
            return simple_intent
        
        # Use small model for most cases
        if len(text) < 500:
            return self._use_small_model(text)
        
        # Only use big model for complex content
        return self._use_premium_model(text)
    
    def _keyword_classification(self, text):
        """Fast, rule-based classification"""
        delegation_patterns = [
            r'\bcan you\b', r'\bplease handle\b', 
            r'\bassign to\b', r'\bfollow up\b'
        ]
        if any(re.search(p, text.lower()) for p in delegation_patterns):
            return 'delegation'
        return None
    
    def batch_process(self, items, max_batch=10):
        """Process in batches to reduce API calls"""
        results = []
        for i in range(0, len(items), max_batch):
            batch = items[i:i+max_batch]
            # Single API call with multiple items
            results.extend(self._batch_api_call(batch))
        return results
```

**Cost Savings:** This approach reduces LLM API costs by 70-90%.

---

### **5. CACHING STRATEGY (CRITICAL FOR PERFORMANCE)**

**Missing from Gemini's approach:**

```python
class MetricCache:
    """
    Cache intermediate calculations to avoid reprocessing
    """
    
    def get_or_calculate(self, cache_key, calculation_func, ttl=3600):
        """
        Check cache first, calculate if missing
        """
        if cached := self.redis.get(cache_key):
            return json.loads(cached)
        
        result = calculation_func()
        self.redis.setex(cache_key, ttl, json.dumps(result))
        return result
    
    def invalidate_pattern(self, pattern):
        """
        Invalidate cache when new data arrives
        """
        keys = self.redis.keys(pattern)
        if keys:
            self.redis.delete(*keys)

# Example usage
cache = MetricCache()

def calculate_response_time_reciprocity(user_id, contact_id, date_range):
    cache_key = f"reciprocity:{user_id}:{contact_id}:{date_range}"
    
    return cache.get_or_calculate(
        cache_key,
        lambda: expensive_calculation(user_id, contact_id, date_range),
        ttl=3600  # Cache for 1 hour
    )
```

---

### **6. INCREMENTAL PROCESSING (EFFICIENCY)**

**Enhancement to Gemini's approach:**

```python
class IncrementalProcessor:
    """
    Only process new/changed data
    """
    
    def __init__(self):
        self.last_processed_timestamp = self.load_checkpoint()
    
    def process_new_emails(self):
        """
        Only fetch emails after last checkpoint
        """
        new_emails = fetch_emails_since(self.last_processed_timestamp)
        
        if not new_emails:
            return  # Nothing to do
        
        # Process only new data
        threads_affected = self.identify_affected_threads(new_emails)
        
        # Recalculate only metrics for affected threads
        self.recalculate_metrics(threads_affected)
        
        # Update checkpoint
        self.save_checkpoint(max(e['date'] for e in new_emails))
    
    def identify_affected_threads(self, new_emails):
        """
        Find which existing threads are impacted
        """
        thread_ids = set()
        for email in new_emails:
            if email.get('thread_id'):
                thread_ids.add(email['thread_id'])
        return thread_ids
```

**Why Critical:** Prevents reprocessing thousands of old emails every time.

---

## **üìä SPECIFIC METRIC CALCULATION IMPROVEMENTS**

### **Response Time Reciprocity (Enhanced)**

**Gemini's approach is good. Add these edge cases:**

```python
def calculate_response_time_reciprocity(thread, user_email):
    """
    Handle edge cases properly
    """
    user_response_times = []
    contact_response_times = []
    
    for i in range(1, len(thread)):
        prev_email = thread[i-1]
        curr_email = thread[i]
        
        time_delta = (curr_email['date'] - prev_email['date']).total_seconds() / 3600
        
        # Skip if response is > 7 days (likely abandoned thread)
        if time_delta > 168:
            continue
        
        # Skip if response is < 1 minute (likely automated)
        if time_delta < 0.017:
            continue
        
        # Skip business hours adjustment
        working_hours_only = calculate_working_hours(prev_email['date'], curr_email['date'])
        
        if curr_email['from'] == user_email:
            contact_response_times.append(working_hours_only)
        else:
            user_response_times.append(working_hours_only)
    
    if not user_response_times or not contact_response_times:
        return None  # Insufficient data
    
    avg_user = statistics.median(user_response_times)  # Use median, not mean
    avg_contact = statistics.median(contact_response_times)
    
    return avg_contact / avg_user if avg_user > 0 else float('inf')

def calculate_working_hours(start_dt, end_dt):
    """
    Only count working hours (M-F, 9-5)
    """
    # Implementation details...
    pass
```

**Key Improvements:**
- Use **median instead of mean** (more robust to outliers)
- Filter **automated responses** (< 1 minute)
- Filter **abandoned threads** (> 7 days)
- Count only **working hours** for fairness

---

### **Context Switch Tax (Simplified)**

**Gemini's LLM approach is expensive. Try this hybrid:**

```python
class ContextClassifier:
    """
    Efficient context detection without heavy LLM
    """
    
    def __init__(self):
        # Pre-define context categories
        self.contexts = {
            'client_work': ['client', 'customer', 'proposal', 'contract'],
            'team_mgmt': ['1:1', 'feedback', 'performance', 'hiring'],
            'product': ['roadmap', 'feature', 'sprint', 'backlog'],
            'operations': ['budget', 'process', 'vendor', 'legal']
        }
    
    def classify(self, email_or_meeting):
        """
        Fast keyword-based classification
        """
        text = (email_or_meeting['subject'] + ' ' + 
                email_or_meeting.get('body', '')).lower()
        
        scores = {}
        for context, keywords in self.contexts.items():
            scores[context] = sum(1 for kw in keywords if kw in text)
        
        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'other'
    
    def count_switches(self, events):
        """
        Count context switches in chronological stream
        """
        if not events:
            return 0
        
        switches = 0
        prev_context = self.classify(events[0])
        
        for event in events[1:]:
            curr_context = self.classify(event)
            if curr_context != prev_context:
                switches += 1
            prev_context = curr_context
        
        return switches
```

**Cost Savings:** 100x cheaper than LLM classification, 90% accuracy.

---

## **üéØ PRIORITY IMPLEMENTATION ORDER**

Tell your coding tools to build in this order:

### **Phase 1: Foundation (Week 1)**
1. ‚úÖ Raw data storage layer
2. ‚úÖ Thread reconstruction
3. ‚úÖ Contact normalization
4. ‚úÖ Basic timeline creation

### **Phase 2: Simple Metrics (Week 2)**
5. ‚úÖ Response Time Reciprocity
6. ‚úÖ Thread Decay Rate
7. ‚úÖ Weekend/Evening Creep
8. ‚úÖ Reactive vs. Proactive Ratio

### **Phase 3: Advanced (Week 3)**
9. ‚úÖ Context Switch Tax (keyword-based)
10. ‚úÖ Meeting ROI Score
11. ‚úÖ Communication Equity Index

### **Phase 4: LLM-Enhanced (Week 4)**
12. ‚úÖ Delegation vs. Execution Ratio
13. ‚úÖ Strategic Focus Alignment
14. ‚úÖ Energy Signature Pattern

---

## **üì¶ RECOMMENDED TECH STACK**

```yaml
Database:
  - PostgreSQL: Raw data, processed data
  - Redis: Caching, real-time metrics
  - TimescaleDB: Time-series metrics storage

Processing:
  - Python: Data pipeline
  - Pandas: Data manipulation
  - spaCy: NLP (lightweight)
  
LLM:
  - OpenAI GPT-3.5: Cheap batch processing
  - GPT-4: Complex classifications only
  - Local model: Sentence transformers for embeddings

Queue:
  - Celery + Redis: Async processing
  - Batch jobs every 15 minutes
```

---

## **üîß CODE STRUCTURE TEMPLATE**

```
data_pipeline/
‚îú‚îÄ‚îÄ extractors/
‚îÇ   ‚îú‚îÄ‚îÄ gmail_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ calendar_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ slack_extractor.py
‚îú‚îÄ‚îÄ processors/
‚îÇ   ‚îú‚îÄ‚îÄ thread_builder.py
‚îÇ   ‚îú‚îÄ‚îÄ contact_unifier.py
‚îÇ   ‚îî‚îÄ‚îÄ timeline_creator.py
‚îú‚îÄ‚îÄ enrichers/
‚îÇ   ‚îú‚îÄ‚îÄ llm_classifier.py
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_analyzer.py
‚îÇ   ‚îî‚îÄ‚îÄ intent_detector.py
‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îú‚îÄ‚îÄ relationship_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ attention_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ leadership_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ strategic_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ sustainability_metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ network_metrics.py
‚îú‚îÄ‚îÄ cache/
‚îÇ   ‚îî‚îÄ‚îÄ metric_cache.py
‚îî‚îÄ‚îÄ scheduler.py
```

---

## **‚ö†Ô∏è CRITICAL GOTCHAS TO AVOID**

1. **Don't recalculate everything on every run** ‚Üí Use incremental processing
2. **Don't use mean for time calculations** ‚Üí Use median (outlier-resistant)
3. **Don't ignore timezone conversions** ‚Üí Everything in UTC, display in user's TZ
4. **Don't skip contact normalization** ‚Üí One person = one identity
5. **Don't use expensive LLM for everything** ‚Üí Tier your approach

---
Excellent! Calculating these advanced metrics from raw email and calendar data will require a robust data pipeline, clever feature engineering, and some sophisticated text analysis. Let's break down how we can approach this for each theme.

The core idea is to transform unstructured (email bodies, meeting descriptions) and semi-structured (headers, timestamps, attendees) data into structured, calculable features.

---

## **Data Sources & Pre-processing Layer**

**1. Email Data (API Access via Google/Outlook):**
* **Headers:** `From`, `To`, `Cc`, `Bcc`, `Subject`, `Date`, `Message-ID`, `In-Reply-To`, `References`
* **Body:** Plain text content
* **Attachments:** Metadata (size, type) - *less critical for these metrics but good to note*

**2. Calendar Data (API Access via Google/Outlook):**
* **Events:** `Organizer`, `Attendees`, `Start Time`, `End Time`, `Duration`, `Title`, `Description`, `Location`, `Status` (accepted, tentative, declined)

**Pre-processing Steps:**

* **Standardization:** Convert all timestamps to a consistent timezone (e.g., UTC) and then to the user's local timezone for reporting.
* **Deduplication:** Ensure unique emails/meetings are processed once.
* **Participant Normalization:** Standardize email addresses (e.g., `john.doe@example.com` and `john@example.com` map to "John Doe").
* **Thread Reconstruction:** Critical for emails using `Message-ID`, `In-Reply-To`, and `References` headers to link emails into conversations.

---

## **Theme 1: ‚ÄúRelationship Velocity & Health‚Äù - Data Pipeline**

**Core Challenge:** Identifying who is "you" and "them," linking communications to specific individuals/groups, and measuring time deltas.

**1. Response Time Reciprocity Score**

* **Data Needed:** Email `From`, `To`, `Date`, `In-Reply-To`/`References` for threading.
* **Calculation Steps:**
    1.  **Thread Identification:** Group emails into conversations using `Message-ID` and `In-Reply-To`/`References` headers. This allows you to reconstruct the sequence of messages.
    2.  **Sender/Receiver Role:** For each email in a thread:
        * If `From` is `User A` and `To`/`Cc` includes `Contact X`, `User A` is the sender, `Contact X` is the receiver.
        * If `From` is `Contact X` and `To`/`Cc` includes `User A`, `Contact X` is the sender, `User A` is the receiver.
    3.  **Response Time Calculation:**
        * When `Contact X` responds to `User A`'s message: `Contact X`'s Response Time = `Date(Contact X's email)` - `Date(User A's last email in thread to Contact X)`.
        * When `User A` responds to `Contact X`'s message: `User A`'s Response Time = `Date(User A's email)` - `Date(Contact X's last email in thread to User A)`.
    4.  **Average Response Times:** Calculate the average response time for `User A` to `Contact X`, and for `Contact X` to `User A`, over a defined period (e.g., 30 days). Filter out automated responses.
    5.  **Reciprocity Score:** `(Average Contact X Response Time) / (Average User A Response Time)`. Special handling for zero response times (e.g., add a small epsilon or cap).
* **LLM Context:** The individual contact, the score, the trend (compare current to previous period), and potentially the subject lines/content of the conversations.

**2. Conversation Thread Decay Rate**

* **Data Needed:** Email `From`, `To`, `Date`, `In-Reply-To`/`References`, thread metadata.
* **Calculation Steps:**
    1.  **Identify "Last Message":** For each completed thread (or threads that haven't had a reply in X days, signaling decay), determine the sender of the very last message in that thread.
    2.  **User vs. Other:** Classify if the last message was sent by `User A` or by "them" (any other participant).
    3.  **Decay Rate:** `(Number of threads where User A sent the last message and no further replies occurred) / (Total number of threads involving User A)`. This can be segmented by contact or domain.
    4.  **Trend Analysis:** Compare this rate over time.
* **LLM Context:** Contact/domain, current decay rate, historical decay rate, perhaps a sample of subject lines from decayed threads.

**3. Collaboration Temperature Map**

* **Data Needed:** Email `From`, `To`, `Cc`, `Date`; Calendar `Organizer`, `Attendees`, `Start Time`, `End Time`.
* **Calculation Steps:**
    1.  **Feature Extraction per Contact/Group per Time Window (e.g., week/month):**
        * **Email Frequency:** Count emails sent to/from the contact/group.
        * **Meeting Frequency:** Count meetings where the contact/group was present with `User A`.
        * **Response Times:** Average response times (from metric #1).
        * **CC Patterns:** Count how often `User A` is CC'ing them, or they are CC'ing `User A`. Also, count how often they are both CC'd on *other* threads (indicating shared context).
    2.  **Normalization & Weighting:** Normalize these features to a 0-1 scale (e.g., using min-max scaling across all contacts for that period). Apply weights based on perceived importance (e.g., meetings might weigh more than emails).
    3.  **Composite Score:** Sum the weighted normalized scores to get a "Collaboration Temperature Score."
    4.  **Trend:** Track this score over time to show warming/cooling.
* **LLM Context:** The contact/group, current score, trend, and the specific factors contributing most to the change (e.g., "meeting frequency dropped").

---

## **Theme 2: ‚ÄúAttention Economics‚Äù - Data Pipeline**

**Core Challenge:** Quantifying mental load, task switching, and accumulating obligations.

**4. Peak Cognitive Load Windows**

* **Data Needed:** Email `Date`, `Time`, `From`, `To`, `Cc`; Calendar `Start Time`, `End Time`.
* **Calculation Steps:**
    1.  **Baseline Activity per Time Slot (e.g., 30-min blocks):**
        * **Meeting Density:** Binary flag (1 if `User A` in a meeting, 0 otherwise). Can be weighted by # of attendees.
        * **Email Volume (Incoming):** Count of emails received by `User A`.
        * **Email Volume (Outgoing):** Count of emails sent by `User A`.
        * **Response Time Impact:** During a time block, average the immediate response times of emails *sent* by `User A` (shorter times might indicate less load or urgent tasks).
    2.  **Combine & Weight:** Assign weights to each factor (e.g., meetings > incoming emails). Sum them for a "Cognitive Load Score" for each time block.
    3.  **Aggregate:** Average scores for similar time blocks across days/weeks to identify patterns (e.g., "Tuesday 2-3 PM").
* **LLM Context:** Specific time windows, the load score, and the dominant contributors (e.g., "high meeting density").

**5. Context Switch Tax**

* **Data Needed:** Email `Subject`, `Body`; Calendar `Title`, `Description`; `Date`, `Time`.
* **Calculation Steps:**
    1.  **Topic Extraction:** This is the most complex part.
        * **LLM/NLP Model:** Use a pre-trained topic modeling LLM (e.g., BERTopic, LDA) or a custom classifier trained on a user's historical data to identify the primary topic of each email and meeting. Categorize topics into broader "contexts" (e.g., "Client X Project," "Internal HR," "Product Roadmap").
        * **Subject/Title Keywords:** A simpler approach is to identify recurring keywords/phrases in subjects and titles.
    2.  **Sequence Events:** Create a chronological stream of all `User A`'s communication events (sending/receiving emails, attending meetings).
    3.  **Context Change Detection:** Iterate through the sequenced events. If the topic/context of event `N` differs from event `N-1`, increment a "context switch" counter.
    4.  **Hourly/Daily Aggregation:** Sum context switches per hour/day.
* **LLM Context:** Average daily switches, common categories involved in switches, and specific examples (e.g., "you switched from X to Y 5 times yesterday").

**6. ‚ÄúReply Debt‚Äù Accumulation Curve**

* **Data Needed:** Email `Date`, `From`, `To`, `Subject`, `In-Reply-To`. Requires tracking email status (replied/unreplied).
* **Calculation Steps:**
    1.  **Identify Unreplied Emails:** For all emails where `User A` is a primary recipient (`To`, not just `Cc`) and hasn't sent a reply *in that thread* within a defined timeframe (e.g., 24-48 hours).
    2.  **Sender Importance Weighting:**
        * **Manual Tagging:** Allow `User A` to tag certain senders/domains as "high importance."
        * **Heuristic:** Leadership, direct reports, key clients = higher weight. Mass newsletters = lower weight.
        * **Historical Interaction:** Senders `User A` frequently responds to quickly get higher weight.
    3.  **Debt Score:** For each unreplied email: `(Current Date - Email Receive Date) * Sender Importance Weight`.
    4.  **Accumulation:** Sum these debt scores hourly/daily to show the total "debt." Segment by sender category.
* **LLM Context:** Total debt score, top N overdue senders/categories, average age of debt.

---

## **Theme 3: ‚ÄúLeadership Patterns‚Äù - Data Pipeline**

**Core Challenge:** Inferring intent and role from communication content and patterns.

**7. Delegation vs. Execution Ratio**

* **Data Needed:** Email `Body`, `From`.
* **Calculation Steps:**
    1.  **Verb Pattern Matching (NLP/LLM):** This requires advanced NLP.
        * **"Delegation" Keywords:** "Can you," "Please handle," "Assign to," "Follow up with," "I need you to," "Delegating this to."
        * **"Execution" Keywords:** "I will," "I'm working on," "I completed," "My task is," "I'll take care of."
        * **"Decision" Keywords:** "I've decided," "The decision is," "We will proceed with," "My call is."
    2.  **Sentence-level Classification:** For each email sent by `User A`, classify sentences or paragraphs into these categories.
    3.  **Email-level Classification:** Aggregate to determine the dominant pattern for the email.
    4.  **Ratio:** Count emails classified as "Delegation," "Execution," "Decision" over time.
* **LLM Context:** Current ratio, trend, and a few sample sentences that exemplify the shift.

**8. Meeting ROI Score**

* **Data Needed:** Calendar `Attendees`, `Start Time`, `End Time`, `Description`; Email `Body`, `Subject` (for post-meeting follow-ups).
* **Calculation Steps:**
    1.  **Action Item/Decision Extraction (NLP/LLM):**
        * Scan meeting descriptions and *follow-up emails from User A or meeting attendees within 24 hours* for phrases like: "Action: [task]", "Decision: [outcome]", "Next Steps:", "Agreed to:".
        * LLM can be trained to identify action items and decisions.
    2.  **Quantify Value:** Count action items and decisions. Each could have a base value (e.g., 1 point per action item, 2 points per decision).
    3.  **Cost:** `Meeting Duration (hours) * Number of Attendees`.
    4.  **ROI Score:** `(Total Value Generated) / (Total Cost)`.
* **LLM Context:** Meeting title, date, ROI score, contributors to low/high score, and suggestions (e.g., "no action items in 3/5 recent meetings").

**9. Communication Equity Index**

* **Data Needed:** Email `From`, `To`, `Cc`, `Date`; Calendar `Attendees`, `Organizer`, `Date`. `User A`'s direct report list.
* **Calculation Steps:**
    1.  **Direct Report Identification:** Requires a configured list of `User A`'s direct reports.
    2.  **Communication Events per Report:** For each direct report, count:
        * Emails sent by `User A` to them (`To`/`Cc`).
        * Emails received by `User A` from them.
        * Meetings where both `User A` and the report were present.
        * *Optional:* Instant messages (if integrated).
    3.  **Time/Volume Allocation:** Sum the "weight" of these interactions for each report over a period (e.g., 30 days). Weights can be applied (e.g., meeting minute = 1 point, email = 0.5 point).
    4.  **Equity Calculation:** Compare each report's allocated share against `1 / (Number of Direct Reports)`. Calculate variance or standard deviation.
* **LLM Context:** List of direct reports, their communication share, and the expected equal share. Highlight significant deviations.

---

## **Theme 4: ‚ÄúStrategic Focus‚Äù - Data Pipeline**

**Core Challenge:** Mapping unstructured communications/meetings to defined strategic priorities.

**10. Time vs. Priority Misalignment Score**

* **Data Needed:** User-defined "Stated Priorities" (OKRs, goals, keywords); Email `Subject`, `Body`; Calendar `Title`, `Description`.
* **Calculation Steps:**
    1.  **Priority Keyword/Topic Mapping:**
        * **User Input:** Allow `User A` to define keywords or phrases associated with each strategic priority (e.g., "Growth" -> "new markets", "sales pipeline", "user acquisition").
        * **LLM Classification:** Use an LLM to classify each email/meeting into one or more of `User A`'s stated priorities based on its content. This is a multi-label classification task.
    2.  **Time Allocation per Event:** For each email/meeting, determine the time `User A` spent on it (e.g., meeting duration, or a fixed time for an email).
    3.  **Aggregate Time per Priority:** Sum the time allocated to each priority over a period.
    4.  **Compare:** Compare `(Actual Time Allocated to Priority X) / (Total Work Time)` with `(Stated Importance of Priority X) / (Sum of Stated Importance)` (if priorities are weighted). Calculate a misalignment score (e.g., squared difference).
* **LLM Context:** List of priorities, actual time spent on each, stated importance, and suggestions for rebalancing.

**11. Reactive vs. Proactive Communication Ratio**

* **Data Needed:** Email `From`, `To`, `In-Reply-To`/`References`.
* **Calculation Steps:**
    1.  **Thread Reconstruction:** Group emails into threads.
    2.  **Identify First Message:** For each thread, identify the very first email.
    3.  **Proactive:** If `User A` sent the first message of a new thread (i.e., `In-Reply-To` is null and `User A` is `From`), it's proactive.
    4.  **Reactive:** If `User A` sent a message that is a reply (`In-Reply-To` is not null), it's reactive.
    5.  **Ratio:** `(Count of Proactive Emails) / (Count of Reactive Emails)`. Can also be `(Proactive) / (Total)`.
* **LLM Context:** Current ratio, trend, and examples of recent proactive/reactive communications.

**12. ‚ÄúFirefighting‚Äù Trend**

* **Data Needed:** Email `Subject`, `Body`; Calendar `Title`, `Description`.
* **Calculation Steps:**
    1.  **Keyword Matching:** Scan `Subject`/`Title`/`Body` for "firefighting" keywords: "urgent," "ASAP," "emergency," "critical issue," "blocker," "immediate action," "crisis," "downtime," etc.
    2.  **Event Counting:** Count emails/meetings containing these keywords.
    3.  **Frequency/Trend:** Track the count over time (daily, weekly) and calculate rolling averages to identify spikes.
    4.  **Root Cause Analysis (LLM assist):** For significant spikes, an LLM could analyze the subjects/bodies of the "firefighting" communications to suggest common themes or root causes.
* **LLM Context:** Current firefighting count/rate, trend, and suggested root causes/solutions from LLM.

---

## **Theme 5: ‚ÄúPersonal Sustainability‚Äù - Data Pipeline**

**Core Challenge:** Identifying work-life boundaries and periods of focused work.

**13. Weekend/Evening Creep Index**

* **Data Needed:** Email `Date`, `Time`; User-defined `Work Hours` (e.g., Mon-Fri, 9 AM - 5 PM).
* **Calculation Steps:**
    1.  **Out-of-Hours Check:** For each email sent by `User A`, check if its `Date`/`Time` falls outside the defined `Work Hours` (e.g., before 9 AM, after 5 PM, or on Saturday/Sunday).
    2.  **Percentage:** `(Count of Emails Sent Outside Work Hours) / (Total Emails Sent)`.
    3.  **Trend:** Track this percentage over time.
    4.  **Optional:** Can also do this for emails *read* if email client integration allows for read receipts or client-side activity logging.
* **LLM Context:** Current percentage, trend, and comparison to healthy baselines.

**14. Single-Player vs. Collaborative Time**

* **Data Needed:** Calendar `Start Time`, `End Time`, `Attendees`; Email `Date`, `Time`, `From`, `To`, `Cc`.
* **Calculation Steps:**
    1.  **Collaborative Time:**
        * **Meetings:** Any time `User A` is in a meeting with 1+ other attendee.
        * **Active Email Threads:** Time spent actively participating in an email thread (e.g., a short window around sending/receiving an email in a thread with others).
    2.  **Solo/Focus Time:**
        * **Calendar Gaps:** Any time on `User A`'s calendar not blocked by a meeting.
        * **Low-Email Periods:** Periods where `User A` receives very few emails and sends none.
        * *Refinement:* Deduct "active email time" from calendar gaps.
        * *LLM assist:* Identify calendar blocks explicitly labeled "Focus Time," "Deep Work," etc.
    3.  **Ratio/Hours:** Calculate total hours for each category per day/week.
* **LLM Context:** Total solo time, total collaborative time, trend, and identified long blocks of focus time.

**15. Energy Signature Pattern**

* **Data Needed:** Email `Date`, `Time`, `Length`, `Sentiment`; Meeting `Participation` (if available from transcript/integration), `Response Times` (from metric #1).
* **Calculation Steps:**
    1.  **Feature Extraction per Time Slot (e.g., hourly):**
        * **Response Times:** Average `User A`'s outgoing response times during that hour (shorter = higher energy).
        * **Email Length:** Average length of emails sent by `User A` (longer might indicate more cognitive effort/detail, or potentially rambling if very long).
        * **Email Sentiment (NLP/LLM):** Analyze sentiment of emails sent by `User A` (more positive = higher energy/mood).
        * **Meeting Participation (if audio processed):** Speaking time, interruption count, sentiment in meetings. (Highly advanced, likely beyond initial scope).
    2.  **Composite Score:** Normalize and weight these features to create an "Energy Score" for each hour.
    3.  **Average Pattern:** Average these hourly scores over several weeks/months to find a typical daily "energy curve."
* **LLM Context:** The hourly energy curve, peak/trough times, and correlations with activities.

---

## **Theme 6: ‚ÄúNetwork Intelligence‚Äù - Data Pipeline**

**Core Challenge:** Mapping relationships beyond direct communication and identifying points of leverage/risk.

**16. Connector Score**

* **Data Needed:** Email `From`, `To`, `Cc`, `Body`.
* **Calculation Steps:**
    1.  **Identify Introduction Patterns (NLP/LLM):** Scan emails sent by `User A` for phrases like: "I'd like to introduce you to," "Meet [Name]," "Connecting you with," "You two should connect."
    2.  **Participant Detection:** Extract the names/emails of the two (or more) parties being introduced, ensuring they were not previously in a thread together.
    3.  **Connection Graph:** Build a graph where `User A` is a node, and lines connect `User A` to contacts. Weight lines by frequency of communication. Add new lines between introduced parties.
    4.  **Connector Score:** Count unique introductions made by `User A` over a period. Could be weighted by the seniority/relevance of the introduced parties.
* **LLM Context:** Current number of introductions, trend, and suggestions for specific people to connect.

**17. Information Bottleneck Index**

* **Data Needed:** Email `From`, `To`, `Cc`, `Bcc`; Defined "Groups" or "Teams."
* **Calculation Steps:**
    1.  **Group Mapping:** Assign each contact to a primary group/team (e.g., "Engineering," "Sales," "Client X"). This can be manual or heuristic based on domain/title.
    2.  **Communication Flow:** For each email thread, identify all unique participants and their respective groups.
    3.  **Bottleneck Detection:** If `User A` is the *only* person (or one of very few) included in an email thread that connects two otherwise distinct groups (i.e., no other person from Group A is communicating directly with Group B in that thread), then `User A` is a potential bottleneck.
    4.  **Index Calculation:** Count such instances over time. Can be weighted by the number of different groups `User A` connects.
* **LLM Context:** Number of identified bottlenecks, the groups involved, and suggestions for direct connections or shared resources.

**18. Influence Ripple Effect**

* **Data Needed:** Email `From`, `To`, `Cc`, `In-Reply-To`/`References`, `Date`.
* **Calculation Steps:**
    1.  **Initiating Message:** Identify emails sent by `User A` that start a new thread or a significant new sub-thread (not just a quick reply).
    2.  **Follow-up Count:** Track how many subsequent emails and meetings are generated *within a defined timeframe* (e.g., 7 days) from that initial message, where those subsequent communications are clearly related to the original message's topic. This involves advanced thread analysis and potentially topic similarity.
    3.  **Ripple Multiplier:** `(Total Subsequent Communications) / 1` (for the initial message).
    4.  **Average/Segmentation:** Average the ripple effect by recipient type (e.g., Leadership, direct reports, vendors).
* **LLM Context:** Average ripple effect, highest/lowest ripple messages, and recipient segments where influence is high/low.

---

## **LLM Integration for Data Pipeline**

LLMs are not just for recommendations; they can be powerful tools within the data pipeline itself for:

* **Topic Modeling:** Automatically categorizing emails/meetings into strategic priorities or communication contexts.
* **Sentiment Analysis:** Extracting sentiment from email bodies to gauge "Energy Signature" or "Collaboration Temperature."
* **Intent Recognition:** Identifying "delegation," "execution," "decision," or "introduction" intent from natural language.
* **Named Entity Recognition (NER):** Extracting key entities (people, projects, clients) to link communications.
* **Summarization:** For root cause analysis of "firefighting" trends, summarizing key issues from a cluster of related emails.

**Architecture for LLM in Pipeline:**

1.  **Raw Data -> Pre-processing -> Feature Store:** Extract basic features (timestamps, senders, recipients, raw text).
2.  **Feature Store -> LLM API Calls (Async/Batch):** Pass chunks of text (email bodies, meeting descriptions) to LLMs for advanced classification, sentiment, topic extraction, etc. This should be a separate, scalable service.
3.  **LLM Outputs -> Enhanced Feature Store:** Store the results (e.g., `email_topic: "Product Roadmap"`, `email_sentiment: "positive"`, `email_intent: "delegation"`).
4.  **Enhanced Feature Store -> Metric Calculation Engine:** Use the enriched data to perform the calculations described above.

---
